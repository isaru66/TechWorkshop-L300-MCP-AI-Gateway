---
title: '6. Implement FinOps Framework for AI Cost Management'
layout: default
nav_order: 7
parent: 'Exercise 04: Configure AI Gateway using Azure API Management'
---

# Exercise 06 - Implement FinOps Framework for AI Cost Management

## Introduction

The [FinOps Framework](https://www.finops.org/framework/) provides a structured approach to cloud financial management, helping organizations optimize AI costs while maintaining performance. In this exercise, you'll implement cost tracking, quota management, and automated alerts using Azure API Management token limits, Azure Monitor custom tables, and Logic Apps for automated subscription management.

By integrating retail pricing data with token consumption metrics, you'll gain visibility into actual AI costs per subscription and automatically enforce cost quotas to prevent budget overruns.

## Description

In this exercise, you will implement the FinOps framework for AI cost management by:
1. Loading retail pricing data into Azure Monitor custom tables
2. Configuring cost quotas for APIM product subscriptions
3. Setting up automated monitoring and alerting
4. Testing the complete cost management workflow
5. Analyzing costs using Azure Workbooks

## Success Criteria

- You have successfully loaded retail pricing data into Azure Monitor custom tables
- You have configured cost quotas for each APIM product subscription
- You have tested API calls and verified token consumption tracking
- You have viewed cost analysis in Azure Workbooks showing actual spending vs. quotas
- You understand how the automated alert system works to disable subscriptions exceeding quotas

## Learning Resources

- [FinOps Framework](https://www.finops.org/framework/)
- [Azure API Management Token Limit Policy](https://learn.microsoft.com/azure/api-management/azure-openai-token-limit-policy)
- [Azure Monitor Custom Logs](https://learn.microsoft.com/azure/azure-monitor/logs/custom-logs-overview)
- [Azure Monitor Data Collection Rules](https://learn.microsoft.com/azure/azure-monitor/essentials/data-collection-rule-overview)
- [Azure Retail Prices API](https://learn.microsoft.com/rest/api/cost-management/retail-prices/azure-retail-prices)
- [Azure OpenAI Pricing](https://azure.microsoft.com/pricing/details/azure-openai/)
- [Azure Monitor Alerts with Logic Apps](https://learn.microsoft.com/azure/azure-monitor/alerts/alerts-logic-apps)

## Key Tasks

### 01: Open the FinOps Framework Jupyter Notebook

The FinOps implementation is automated through a Jupyter notebook that orchestrates the entire cost management workflow.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. In VS Code, navigate to the `src/02-api-gateway-policy` folder in your workspace.

1. Open the file `finops-framework.ipynb`.

1. Ensure you have the Jupyter extension installed in VS Code (it should have been installed during the initial setup).

1. Select the Python kernel when prompted (use the Python environment where you installed the requirements).

1. Review the notebook structure - it contains the following key sections:
   - **Initialize notebook variables**: Configure deployment settings
   - **Verify Azure CLI**: Ensure proper authentication
   - **Verify azd deployment**: Confirm resources are deployed
   - **Get environment values**: Retrieve deployment outputs
   - **Display retail pricing**: View current AI model pricing
   - **Load pricing data**: Import pricing into Azure Monitor
   - **Load subscription quotas**: Configure cost limits
   - **Execute test runs**: Generate sample usage data
   - **View dashboards**: Analyze costs in workbooks

{: .note }
> This notebook automates the FinOps framework implementation. You can run all cells sequentially or execute them step by step for better understanding.

</details>

### 02: Verify Azure Developer CLI deployment

Before running the FinOps notebook, ensure that your Azure resources have been deployed successfully using `azd up`.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. Open a terminal in VS Code (**Terminal** > **New Terminal**).

1. Navigate to the repository root:
   ```bash
   cd c:\DEV\TechWorkshop\TechWorkshop-L300-MCP-AI-Gateway
   ```

1. Check the azd environment status:
   ```bash
   azd env get-values
   ```

1. You should see output containing key deployment values such as:
   - `apim_gateway_url`: Your API Management gateway URL
   - `apim_service_name`: Your APIM service name
   - `pricingDCREndpoint`: Data Collection Rule endpoint for pricing
   - `subscriptionQuotaDCREndpoint`: Data Collection Rule endpoint for quotas
   - `apim_subscriptions`: JSON array of subscription keys

1. If the command fails or returns empty values, run the deployment:
   ```bash
   azd up
   ```

1. Once deployment completes successfully, proceed to the next step.

{: .note }
> The `azd up` command deploys all required Azure resources including APIM, Azure AI Foundry, Data Collection Rules, Log Analytics Workspace, and Azure Monitor workbooks.

</details>

### 03: Initialize and configure the FinOps notebook

In this step, you'll configure the notebook variables to match your deployment settings and verify connectivity to Azure.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. In the `finops-framework.ipynb` notebook, locate Cell 3 (Initialize notebook variables).

1. Review the configuration variables:
   - `resource_group_name`: Resource group for the lab
   - `aiservices_config`: AI Foundry location configuration
   - `models_config`: Azure OpenAI model definitions with pricing SKUs
   - `apim_products_config`: Product tiers with token limits and cost quotas
   - `apim_subscriptions_config`: Subscription assignments to products

1. **Optional**: Modify the configuration to match your requirements:
   ```python
   apim_products_config = [
       {"name": "platinum", "displayName": "Platinum Product", "tpm": 2000, 
        "tokenQuota": 1000000, "tokenQuotaPeriod": "Monthly", "costQuota": 15},
       {"name": "gold", "displayName": "Gold Product", "tpm": 1000, 
        "tokenQuota": 1000000, "tokenQuotaPeriod": "Monthly", "costQuota": 10}, 
       {"name": "silver", "displayName": "Silver Product", "tpm": 500, 
        "tokenQuota": 1000000, "tokenQuotaPeriod": "Monthly", "costQuota": 5}
   ]
   ```

1. Run Cell 3 to initialize the variables. You should see:
   ```
   âœ“ Notebook initialized
   ```

1. Run Cell 5 (Verify Azure CLI) to confirm authentication:
   ```python
   output = utils.run("az account show", ...)
   ```

1. You should see output showing:
   - Current user email
   - Tenant ID
   - Subscription ID

{: .note }
> The configuration defines three product tiers (Platinum, Gold, Silver) with different cost quotas ($15, $10, $5). The FinOps framework will automatically enforce these limits.

</details>

### 04: Load retail pricing data into Azure Monitor

This step fetches current AI model pricing from the Azure Retail Prices API and loads it into a custom Azure Monitor table for cost calculations.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. In the notebook, run Cell 9 (Display retail pricing info) to view current pricing:
   ```python
   prices = requests.get(f"https://prices.azure.com/api/retail/prices?...")
   ```

1. You should see a table displaying pricing for each model in your configured region:
   
   | Region | SKU | Retail Price (per 1K tokens) |
   |--------|-----|------------------------------|
   | swedencentral | GPT 5.2 chat inp Gl | $0.0025 |
   | swedencentral | GPT 5.2 chat opt Gl | $0.0100 |

1. Run Cell 11 (Load pricing data into Azure Monitor) to import prices:
   ```python
   client = LogsIngestionClient(endpoint=pricing_dcr_endpoint, ...)
   ```

1. The script will:
   - Fetch retail prices for all configured models
   - Calculate per-1K-token costs for input and output tokens
   - Upload pricing data to Azure Monitor custom table using Data Collection Rules

1. Verify successful upload - you should see messages like:
   ```
   â„¹ï¸ Adding model gpt-5.2-chat (source: 1M) with input / output tokens price 2.5 / 10.0
   âœ“ Upload succeeded for model gpt-5.2-chat
   ```

1. **Understanding the pricing data**:
   - Input tokens are typically cheaper than output tokens
   - Prices vary significantly between models (e.g., GPT-5-nano vs GPT-5.2-chat)
   - Global Standard SKUs may have different pricing than regional deployments

{: .note }
> The pricing data is loaded into a custom Azure Monitor table called `PricingData_CL`. This data is used by Kusto queries in the Cost Analysis workbook to calculate actual spending based on token consumption.

</details>

### 05: Configure subscription cost quotas

In this step, you'll load cost quota limits for each APIM subscription into Azure Monitor, enabling automated quota enforcement.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. In the notebook, run Cell 13 (Load Subscription Quota) to configure quotas:
   ```python
   client = LogsIngestionClient(endpoint=subscription_quota_dcr_endpoint, ...)
   ```

1. The script will:
   - Match each subscription to its product tier
   - Extract the cost quota from the product configuration
   - Upload quota data to Azure Monitor custom table

1. Verify successful upload - you should see messages like:
   ```
   â„¹ï¸ Adding subscription1 with cost quota 15
   âœ“ Upload succeeded for subscription1
   ```

1. **How quotas work in the FinOps framework**:
   - Each product tier has a defined `costQuota` (in USD)
   - Subscriptions assigned to a product inherit that quota
   - Azure Monitor alerts compare actual spending against quotas
   - Logic Apps automatically disable subscriptions when quotas are exceeded

1. **Example quota configuration**:
   - **Platinum** ($15): High-value applications with generous budgets
   - **Gold** ($10): Standard production applications
   - **Silver** ($5): Development/testing environments

{: .note }
> The quota data is stored in a custom Azure Monitor table called `SubscriptionQuota_CL`. Azure Monitor alert rules query this table along with token consumption data to detect quota violations.

</details>

### 06: Test the FinOps implementation with Azure OpenAI SDK

Now you'll generate test traffic using the Azure OpenAI Python SDK to simulate real-world API usage and validate cost tracking.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. In the notebook, locate Cell 15 (Execute multiple runs using Azure OpenAI Python SDK).

1. Review the test configuration:
   ```python
   runs = 10  # Number of test requests
   sleep_time_ms = 100  # Delay between requests
   ```

1. **Optional**: Adjust the test parameters for your scenario:
   - Increase `runs` to 50-100 for more comprehensive testing
   - Modify `sleep_time_ms` to simulate different traffic patterns
   - The script randomly selects subscriptions and models for each request

1. Run Cell 15 to execute the test:
   ```python
   for i in range(runs):
       apim_subscription = random.choice(apim_subscriptions)
       openai_model = random.choice(models_config)
       client = AzureOpenAI(azure_endpoint=..., api_key=...)
       response = client.chat.completions.create(...)
   ```

1. You should see output like:
   ```
   â–¶ï¸ Run 1/10: [subscription1 w/ gpt-5.2-chat] ðŸ’¬ I don't have access to real-time weather data...
   â–¶ï¸ Run 2/10: [subscription3 w/ gpt-5-nano] ðŸ’¬ I cannot provide current weather information...
   âŒ Run 3/10: [subscription3 w/ gpt-4.1] Error: Rate limit exceeded...
   ```

1. **Understanding the test results**:
   - Successful responses (â–¶ï¸): Requests processed normally
   - Rate limit errors (âŒ): Token per minute (TPM) limit hit for that product
   - Each request generates token consumption data tracked in Azure Monitor

1. **What happens behind the scenes**:
   - APIM receives the request and validates the subscription key
   - Token limit policy checks TPM quota for the product
   - Request is forwarded to Azure AI Foundry model endpoint
   - Response tokens are counted and logged to Azure Monitor
   - Emit token metric policy records consumption for cost calculation

{: .note }
> The random selection of subscriptions and models simulates a multi-tenant environment where different users consume various AI models at different rates.

</details>

### 07: Analyze costs using Azure Workbooks

Finally, you'll use Azure Workbooks to visualize costs, compare spending against quotas, and identify optimization opportunities.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. Navigate to the [Azure Portal](https://portal.azure.com/).

1. Search for and open your **Log Analytics workspace** (named like `law-lab-02-api-gateway-policy-xxxx`).

1. In the left menu, select **Workbooks** under **General**.

1. Click on the **Cost Analysis** workbook (deployed by `azd up`).

1. The workbook displays:
   - **Total Costs by Subscription**: Bar chart showing spending per subscription
   - **Cost vs. Quota**: Comparison of actual costs against configured limits
   - **Model Usage**: Breakdown of costs by AI model
   - **Token Consumption Trends**: Time-series chart of token usage
   - **Quota Compliance**: Percentage of quota consumed per subscription

1. **Interpreting the Cost Analysis**:
   - ðŸŸ¢ **Green**: Subscription is under 70% of quota (healthy)
   - ðŸŸ¡ **Yellow**: Subscription is 70-90% of quota (warning)
   - ðŸ”´ **Red**: Subscription exceeded quota (should be disabled by alert)

1. **Optional**: Open the **Azure OpenAI Insights** workbook for additional metrics:
   - Request rates and latency
   - Error rates by model and subscription
   - Geographic distribution of requests
   - Model performance comparison

1. **Optional**: Open the **Alerts** workbook to view:
   - Fired alerts for quota violations
   - Alert history and trends
   - Logic App execution logs

1. **Example Cost Analysis Query** (you can run this in Log Analytics):
   ```kusto
   // Calculate actual spending per subscription
   ApiManagementGatewayLlmLog
   | where TimeGenerated > ago(24h)
   | join kind=inner (PricingData_CL) on $left.Model == $right.Model_s
   | extend InputCost = PromptTokens * InputTokensPrice_d / 1000
   | extend OutputCost = CompletionTokens * OutputTokensPrice_d / 1000
   | extend TotalCost = InputCost + OutputCost
   | summarize ActualSpending = sum(TotalCost) by Subscription = SubscriptionName
   | join kind=inner (SubscriptionQuota_CL) on $left.Subscription == $right.Subscription_s
   | extend QuotaRemaining = CostQuota_d - ActualSpending
   | extend PercentageUsed = (ActualSpending / CostQuota_d) * 100
   | project Subscription, ActualSpending, CostQuota = CostQuota_d, 
             QuotaRemaining, PercentageUsed
   | order by PercentageUsed desc
   ```

{: .note }
> The Cost Analysis workbook uses Kusto queries to join token consumption logs with pricing data and quota configurations, providing real-time cost visibility without requiring manual calculations.

</details>

### 08: Understanding the automated alert workflow

Learn how Azure Monitor alerts and Logic Apps work together to automatically enforce cost quotas.

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. In the Azure Portal, navigate to your **API Management instance**.

1. In the left menu, select **Alerts** under **Monitoring**.

1. Click **Alert rules** to view configured rules.

1. You should see alert rules named like:
   - `Subscription Quota Exceeded - subscription1`
   - `Subscription Quota Exceeded - subscription2`

1. Click on an alert rule to view its configuration:
   - **Signal**: Custom log search query
   - **Query**: Joins token consumption, pricing, and quota tables
   - **Threshold**: Alert when actual spending > cost quota
   - **Action Group**: Triggers Logic App to disable subscription

1. **How the alert workflow works**:
   ```
   1. Token consumption logged â†’ Azure Monitor custom table
   2. Alert rule runs query every 5 minutes
   3. Query calculates: actual spending vs. quota
   4. If spending > quota â†’ Alert fires
   5. Alert triggers Action Group
   6. Action Group calls Logic App
   7. Logic App uses APIM REST API to disable subscription
   8. Optional: Logic App sends email notification
   ```

1. **View Logic App execution**:
   - Navigate to your **Logic App** resource
   - Select **Runs history** to see triggered executions
   - Click on a run to view the execution details
   - Verify successful API calls to disable subscriptions

1. **Sample alert query** (used by the alert rule):
   ```kusto
   ApiManagementGatewayLlmLog
   | where TimeGenerated > ago(5m)
   | where SubscriptionName == "subscription1"
   | join kind=inner (PricingData_CL | where TimeGenerated > ago(1d)) 
       on $left.Model == $right.Model_s
   | extend Cost = (PromptTokens * InputTokensPrice_d + 
                    CompletionTokens * OutputTokensPrice_d) / 1000
   | summarize TotalCost = sum(Cost)
   | join kind=inner (SubscriptionQuota_CL | where TimeGenerated > ago(1d) 
       and Subscription_s == "subscription1") on $left.SubscriptionName == $right.Subscription_s
   | where TotalCost > CostQuota_d
   ```

1. **Best practices for alert configuration**:
   - Set alert frequency to 5-15 minutes for near-real-time enforcement
   - Use separate alert rules per subscription for granular control
   - Configure action groups to send notifications before disabling (warning at 80%, disable at 100%)
   - Test alert rules manually using "Test" button before deploying to production

{: .note }
> In a production environment, you may want to implement a multi-stage alert system: send warnings at 70% and 90% quota usage, and only disable subscriptions at 100% after human review.

</details>

### 09: Verify subscription management

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

1. In the Azure Portal, navigate to your **API Management instance**.

1. In the left menu, select **Subscriptions** under **APIs**.

1. Review the list of subscriptions created by the deployment:
   - subscription1 (Platinum tier - $15 quota)
   - subscription2 (Gold tier - $10 quota)
   - subscription3 (Silver tier - $5 quota)
   - subscription4 (Silver tier - $5 quota)

1. Click on a subscription to view details:
   - **State**: Active / Suspended
   - **Primary key**: Used for API authentication
   - **Product**: Associated product tier
   - **User**: Owner of the subscription

1. **Manually disable a subscription** (for testing):
   - Select a subscription
   - Click **...** (More options)
   - Select **Suspend**
   - Confirm the action

1. **Test the disabled subscription**:
   - Copy the subscription key
   - Try making an API call using that key
   - You should receive an HTTP 401 or 403 error: "Access denied"

1. **Re-enable the subscription**:
   - Select the suspended subscription
   - Click **...** (More options)
   - Select **Activate**
   - Confirm the action

{: .note }
> When an alert fires due to quota violation, the Logic App automatically suspends the subscription using the APIM Management API. Users receive an error until the quota is reset (typically monthly) or an administrator manually re-enables access.

</details>

### 10: FinOps best practices and optimization tips

<details markdown="block">
<summary><strong>Expand this section to view the solution</strong></summary>

Based on the FinOps Framework principles, here are recommended practices for ongoing AI cost management:

**1. Visibility & Allocation**
- **Tag all resources**: Use Azure tags to track costs by team, project, or cost center
- **Implement showback/chargeback**: Use Azure Cost Management to allocate AI costs to business units
- **Regular cost reviews**: Schedule monthly reviews of the Cost Analysis workbook
- **Monitor trends**: Watch for unexpected spikes in token consumption

**2. Optimization**
- **Right-size model selection**: Use smaller models (e.g., GPT-5-nano) for simple tasks
- **Optimize prompts**: Reduce unnecessary tokens in system messages and user prompts
- **Enable caching**: Use Azure OpenAI's prompt caching to reduce redundant token consumption
- **Implement semantic caching**: Cache similar queries at the application layer
- **Batch operations**: Process multiple requests together when possible

**3. Governance & Control**
- **Implement tiered access**: Assign users to appropriate product tiers based on needs
- **Regular quota reviews**: Adjust quotas based on actual usage patterns and business value
- **Cost anomaly detection**: Set up additional alerts for unusual spending patterns
- **Approval workflows**: Require approval for quota increases above certain thresholds

**4. Automation**
- **Auto-scaling quotas**: Implement Logic Apps to automatically adjust quotas based on business rules
- **Scheduled reports**: Send weekly cost summaries to stakeholders via email
- **Predictive alerting**: Use Azure Machine Learning to forecast quota exhaustion
- **Resource tagging automation**: Auto-tag API requests with metadata for granular cost tracking

**5. Cultural Change (FinOps Principle)**
- **Cost awareness training**: Educate developers on AI cost implications
- **Cost-conscious development**: Include cost considerations in sprint planning
- **Shared responsibility**: Make cost optimization everyone's responsibility, not just finance
- **Celebrate wins**: Recognize teams that successfully optimize AI spending

**6. Model-Specific Optimizations**
- **GPT-5-nano**: Use for simple classification, extraction, and summarization
- **GPT-5-mini**: Balance of cost and capability for most tasks
- **GPT-5.2**: Reserve for complex reasoning, coding, and creative tasks
- **Completion vs. Chat models**: Choose based on actual use case requirements

**7. Load Balancing & Resilience**
- **Multiple backend pools**: Distribute traffic across regions for cost optimization
- **Failover strategies**: Implement graceful degradation to cheaper models during high load
- **Priority queuing**: Route high-value requests to premium models, others to cost-effective options

**8. Continuous Improvement**
- **A/B testing**: Compare model performance vs. cost regularly
- **Feedback loops**: Collect user satisfaction data to validate model selection
- **Regular audits**: Review and remove unused subscriptions and products
- **Stay updated**: Monitor Azure pricing changes and new model releases

{: .note }
> The FinOps Framework emphasizes that cost optimization is an ongoing practice, not a one-time setup. Schedule quarterly reviews of your implementation and adjust based on business changes and new Azure capabilities.

</details>

## Summary

Congratulations! You have successfully implemented the FinOps Framework for AI cost management using Azure API Management and Azure Monitor. You now have:

âœ… **Automated pricing data collection** from Azure Retail Prices API  
âœ… **Cost quota enforcement** per APIM subscription and product tier  
âœ… **Real-time cost tracking** with custom Azure Monitor tables  
âœ… **Automated alerts and remediation** using Logic Apps  
âœ… **Comprehensive cost visibility** through Azure Workbooks  

### Key Takeaways

1. **FinOps is a cultural shift**: Cost optimization requires collaboration between engineering, finance, and business teams.

2. **Visibility enables optimization**: You can't optimize what you can't measure - comprehensive cost tracking is the foundation.

3. **Automation scales governance**: Manual quota enforcement doesn't scale; automated alerts and remediation ensure consistent policy enforcement.

4. **Right-sizing matters**: Using the appropriate AI model for each task can reduce costs by 10-100x without sacrificing quality.

5. **Continuous monitoring**: AI cost management is an ongoing practice that requires regular review and adjustment.

### Next Steps

- **Exercise 05**: Explore advanced **MCP (Model Context Protocol)** integration patterns
- **Production deployment**: Adapt this implementation to your organization's requirements
- **Advanced features**: Implement predictive cost forecasting using Azure Machine Learning
- **Integration**: Connect cost data to your existing FinOps or cloud management platforms

### Additional Resources

- [FinOps Foundation](https://www.finops.org/)
- [Azure FinOps Guide](https://learn.microsoft.com/azure/cost-management-billing/finops/)
- [Azure OpenAI Cost Management](https://learn.microsoft.com/azure/ai-services/openai/how-to/manage-costs)
- [APIM Token Limit Policy](https://learn.microsoft.com/azure/api-management/azure-openai-token-limit-policy)
- [Azure Monitor Custom Logs](https://learn.microsoft.com/azure/azure-monitor/logs/custom-logs-overview)

---

{: .note }
> **Clean up resources**: When you're finished with this lab, use the clean-up notebook to remove all deployed resources and avoid unnecessary charges: `src/02-api-gateway-policy/clean-up-resources.ipynb`
